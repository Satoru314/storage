# 想定質問・疑念点まとめ

## 【アーキテクチャ設計について】

### Q1: なぜ直接アップロード方式を選んだのですか？サーバー経由の方がシンプルでは？
**回答のポイント**: 
- **スケーラビリティ**: サーバーリソースの制約を回避
- **パフォーマンス**: 転送速度の最適化、同時アップロード対応
- **コスト効率**: サーバー帯域使用量の削減
- **トレードオフ**: 実装複雑性 vs 運用メリットの判断

### Q2: 3層構成にした理由は？2層では不足ですか？
**回答のポイント**: 
- **責務の分離**: プレゼンテーション、ビジネスロジック、データ永続化
- **スケール戦略**: 各層を独立してスケールアウト可能
- **保守性**: 変更影響の局所化、テスタビリティ向上

### Q3: メタデータをRDBで管理する理由は？オブジェクトストレージだけでは？
**回答のポイント**: 
- **検索性能**: インデックスを活用した高速検索
- **整合性**: ACID特性による データ整合性保証
- **拡張性**: 将来的な複雑な検索・集計機能への対応

---

## 【セキュリティについて】

### Q4: Presigned URLって本当に安全ですか？
**回答のポイント**: 
- **有効期限**: 5分間の制限で最小限のリスク
- **スコープ限定**: 特定オブジェクトのみアクセス可能
- **一時的なアクセス権**: 永続的な認証情報を渡さない
- **実装経験**: 5分間の制限で実際にテスト済み、期限切れを確認

### Q5: ファイルの内容検証はしないのですか？
**回答のポイント**: 
- **MIMEタイプ検証の限界**: Content-Typeヘッダーは偽装可能
- **ウイルススキャンの必要性**: 本格運用時には必須
- **拡張案**: Lambda関数でのファイル内容検証、ClamAV統合

### Q6: 認証機能がないように見えますが...？
**回答のポイント**: 
- **今回は基本機能の設計**: アップロード機能に焦点
- **認証レイヤーの追加は容易**: ミドルウェアでの実装可能
- **拡張案**: JWTトークン、OAuth2.0統合、ユーザー管理

---

## 【パフォーマンス・スケーラビリティ】

### Q7: 同時大量アップロードに対応できますか？
**回答のポイント**: 
- **S3の無制限スケーラビリティ**: AWSの分散アーキテクチャ活用
- **バックエンド分散化**: ロードバランサー、複数インスタンス対応
- **懸念点**: データベースのコネクション数、レート制限設定

### Q8: ファイルサイズ制限50MBの根拠は？
**回答のポイント**: 
- **ユーザビリティ**: アップロード時間とユーザー体験のバランス
- **メモリ使用量**: ブラウザでの処理可能範囲
- **ネットワーク帯域**: モバイル環境での現実的な制限
- **実装経験**: 実際のテストでの快適性確認

### Q9: CDN使わなくて大丈夫ですか？
**回答のポイント**: 
- **CloudFrontとの組み合わせ想定**: 本格運用時には導入
- **初期コスト vs パフォーマンス**: 段階的な最適化戦略
- **地域展開**: グローバル展開時の必須要件

---

## 【運用・保守について】

### Q10: アップロード失敗時のガベージコレクションは？
**実装漏れ**: 重要な指摘点、cleanup処理の実装が必要
**解決案**: 
- **定期的なバッチ処理**: cron jobでの孤立ファイル削除
- **ステータスベースの削除**: 'requested'状態で放置されたレコード
- **S3ライフサイクル**: 未完了アップロードの自動削除設定

### Q11: ログ・監視はどう考えていますか？
**回答のポイント**: 
- **Echo middleware**: アクセスログ、エラーログの標準出力
- **AWS CloudWatch**: ログ集約、メトリクス監視
- **アラート設定**: エラー率、レスポンス時間の閾値監視
- **実装経験**: ログ出力の重要性を実感、デバッグ効率向上

### Q12: データベースのバックアップ戦略は？
**回答のポイント**: 
- **PostgreSQLの標準機能**: pg_dump、ポイントインタイムリカバリ
- **S3とのデータ整合性**: メタデータとファイルの同期確保
- **災害対策**: マルチAZ配置、レプリケーション

---

## 【コスト最適化】

### Q13: S3のコストって大丈夫ですか？
**回答のポイント**: 
- **ストレージクラス選択**: Standard, IA, Archiveの使い分け
- **ライフサイクル設定**: 自動的なクラス移行
- **試算**: 月間1000ファイル（平均2MB）で約$5程度

### Q14: データ転送量が多くなったらどうしますか？
**回答のポイント**: 
- **CloudFront導入**: エッジキャッシュでの転送量削減
- **リージョン選択**: ユーザーに近いリージョンの活用
- **圧縮**: 画像最適化、WebP形式への変換

---

## 【実装の詳細】

### Q15: エラーハンドリングが甘くないですか？
**実装経験**: 
- **実際に遭遇したエラー**: AWS認証情報読み込み失敗、DBカラム名不一致
- **改善点**: より詳細なエラー分類、ユーザーフレンドリーなメッセージ
- **ログ出力**: 運用時のトラブルシューティング対応

### Q16: テストはどう書きますか？
**回答のポイント**: 
- **単体テスト**: Go testパッケージ、React Testing Library
- **統合テスト**: testcontainersでのDB、S3 mock活用
- **実装課題**: Presigned URLのテスト方法、有効期限検証

### Q17: デプロイ・CI/CDはどう考えますか？
**回答のポイント**: 
- **Docker化**: マルチステージビルド、軽量イメージ作成
- **GitHub Actions**: 自動テスト、ビルド、デプロイパイプライン
- **環境分離**: dev, staging, prod環境の設定管理

---

## 【設計判断への疑念】

### Q18: 直接S3アップロードって複雑じゃないですか？バックエンド経由の方が簡単では？
**回答のポイント**: 
- **パフォーマンス vs 複雑性のトレードオフ**: 長期的なメリット重視
- **実装経験**: 実際にやってみたら思ったより簡単だった
- **フロントエンドの学習コスト**: 一度理解すれば再利用可能

### Q19: メタデータとファイルが分離されてて整合性大丈夫？
**重要な指摘**: データ整合性の課題
**解決案**: 
- **トランザクション的な処理**: 2段階コミット的なアプローチ
- **cleanup機能**: 定期的な整合性チェック
- **監視・アラート**: 不整合検出の自動化

### Q20: この設計、スケールしますか？
**回答のポイント**: 
- **水平スケール戦略**: ステートレス設計、DB分散
- **マイクロサービス化への道筋**: 機能分割、API Gateway活用
- **ボトルネック特定**: 段階的な最適化アプローチ

---

## 【追加で深掘りされそうなポイント】

### セキュリティ深掘り
- **OWASP Top 10への対応**
- **ペネトレーションテストの必要性**
- **個人情報保護法への準拠**

### 運用深掘り
- **SLAの設定**（99.9%可用性など）
- **障害時の復旧手順**
- **パフォーマンスチューニング**

### ビジネス観点
- **競合サービスとの差別化**
- **収益モデル**（従量課金、定額制など）
- **法的リスク**（著作権、プライバシー）